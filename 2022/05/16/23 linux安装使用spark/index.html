
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>linux安装使用spark - 杨的个人博客</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="杨笑源, yangxiaoyuan,"> 
    <meta name="description" content="1 Spark简介2 安装Spark
实验环境：宿主机操作系统: Windows10虚拟机软件：VMware Workstation虚拟机操作系统：Ubuntu2004LTS

2.1 安装scal,"> 
    <meta name="author" content="Xiaoyuan yang"> 
    <link rel="alternative" href="atom.xml" title="杨的个人博客" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
    
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:title" content="linux安装使用spark - 杨的个人博客"/>
    <meta name="twitter:description" content="1 Spark简介2 安装Spark
实验环境：宿主机操作系统: Windows10虚拟机软件：VMware Workstation虚拟机操作系统：Ubuntu2004LTS

2.1 安装scal,"/>
    
    
    
    
    <meta property="og:site_name" content="杨的个人博客"/>
    <meta property="og:type" content="object"/>
    <meta property="og:title" content="linux安装使用spark - 杨的个人博客"/>
    <meta property="og:description" content="1 Spark简介2 安装Spark
实验环境：宿主机操作系统: Windows10虚拟机软件：VMware Workstation虚拟机操作系统：Ubuntu2004LTS

2.1 安装scal,"/>
    
<link rel="stylesheet" href="/css/diaspora.css">

<meta name="generator" content="Hexo 6.0.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">杨的个人博客</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="http://example.com"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">linux安装使用spark</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">linux安装使用spark</h1>
        <div class="stuff">
            <span>五月 16, 2022</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Ubuntu/" rel="tag">Ubuntu</a></li></ul>


        </div>
        <div class="content markdown">
            <h2 id="1-Spark简介"><a href="#1-Spark简介" class="headerlink" title="1 Spark简介"></a>1 Spark简介</h2><h2 id="2-安装Spark"><a href="#2-安装Spark" class="headerlink" title="2 安装Spark"></a>2 安装Spark</h2><blockquote>
<p>实验环境：<br>宿主机操作系统: Windows10<br>虚拟机软件：VMware Workstation<br>虚拟机操作系统：Ubuntu2004LTS</p>
</blockquote>
<h3 id="2-1-安装scala"><a href="#2-1-安装scala" class="headerlink" title="2.1 安装scala"></a>2.1 安装scala</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载deb包</span></span><br><span class="line">hadoop@hadoop1:~$ wget https://downloads.lightbend.com/scala/2.13.4/scala-2.13.4.deb</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">hadoop@hadoop1:~$ sudo dpkg --install scala-2.13.4.deb</span><br></pre></td></tr></table></figure>

<h3 id="2-2-安装spark"><a href="#2-2-安装spark" class="headerlink" title="2.2 安装spark"></a>2.2 安装spark</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装spark</span></span><br><span class="line">hadoop@hadoop1:~$ wget https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop3.2.tgz</span><br><span class="line">hadoop@hadoop1:~$ tar -zxvf spark-3.0.3-bin-hadoop3.2.tgz</span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">mv</span> spark-3.0.3-bin-hadoop3.2 spark-3.0.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line">hadoop@hadoop1:~$ sudo vi /etc/profile.d/spark.sh</span><br><span class="line">添加：</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/home/hadoop/spark-3.0.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HBASE_HOME</span>/bin</span><br><span class="line"></span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">source</span> /etc/profile.d/spark.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置spark</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">cd</span> spark-3.0.3/conf/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置slaves</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">cp</span> slaves.template slaves</span><br><span class="line">hadoop@hadoop1:~$ vi slaves</span><br><span class="line">修改为：（多节点可添加配置）</span><br><span class="line">hadoop1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置spark-env.sh</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">cp</span> spark-env.sh.template  spark-env.sh</span><br><span class="line">hadoop@hadoop1:~$ vi  spark-env.sh</span><br><span class="line">添加：</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/hadoop/jdk1.8.0_321/</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/hadoop-3.2.3/</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/home/hadoop/hadoop-3.2.3/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/home/hadoop/scala-2.13.4/</span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_HOST=hadoop1</span><br><span class="line"><span class="built_in">export</span> SPARK_PID_DIR=/home/hadoop/spark-3.0.3/data</span><br><span class="line"><span class="built_in">export</span> SPARK_LOCAL_DIR=/home/hadoop/spark-3.0.3</span><br><span class="line"><span class="built_in">export</span> SPARK_EXECUTOR_MEMORY=512M</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_MEMORY=4G</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置spark-defaults.conf</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">cp</span> spark-defaults.conf.template  spark-defaults.conf</span><br><span class="line">hadoop@hadoop1:~$ vi spark-defaults.conf</span><br><span class="line">添加：</span><br><span class="line">spark.master                     spark://hadoop1:7077</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="variable">$SPARK_HOME</span>/sbin/start-all.sh</span><br><span class="line">hadoop@hadoop1:~$ jps</span><br><span class="line">出现：</span><br><span class="line">35568 Master  （主节点）</span><br><span class="line">35733 Worker  （工作节点）</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时可以通过web访问spark：http://192.168.17.100:8080/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止服务</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="variable">$SPARK_HOME</span>/sbin/stop-all.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-3-运行测试程序"><a href="#2-3-运行测试程序" class="headerlink" title="2.3 运行测试程序"></a>2.3 运行测试程序</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行测试程序</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="variable">$SPARK_HOME</span>/bin/run-example SparkPi 10</span><br><span class="line"><span class="comment"># 通过访问网址查看结果：http://hadoop1:8080/cluster</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动spark-shell</span></span><br><span class="line">hadoop@hadoop1:~$ <span class="variable">$SPARK_HOME</span>/bin/spark-shell</span><br><span class="line"></span><br><span class="line">hadoop@hadoop1:~$ val textFile=sc.textFile(<span class="string">&quot;file:///home/hadoop/spark-3.0.3/README.md&quot;</span>)</span><br><span class="line">hadoop@hadoop1:~$ textFile.count()</span><br><span class="line">出现结果为：</span><br><span class="line">res3: Long = 108 即运行成功</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出spark-shell</span></span><br><span class="line">hadoop@hadoop1:~$ :quit</span><br></pre></td></tr></table></figure>

<h3 id="2-4-安装Jupyter-notebook和python3"><a href="#2-4-安装Jupyter-notebook和python3" class="headerlink" title="2.4 安装Jupyter notebook和python3"></a>2.4 安装Jupyter notebook和python3</h3><p>linux安装jupyter：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新源</span></span><br><span class="line">hadoop@hadoop1:~$ sudo apt update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装python</span></span><br><span class="line">hadoop@hadoop1:~$ sudo apt install python3-pip python3-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为Jupyter创建虚拟环境</span></span><br><span class="line">hadoop@hadoop1:~$ sudo -H pip3 install --upgrade pip</span><br><span class="line">hadoop@hadoop1:~$ sudo -H pip3 install virtualenv</span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">mkdir</span> ~/my_project_dir</span><br><span class="line">hadoop@hadoop1:~$ <span class="built_in">cd</span> ~/my_project_dir</span><br><span class="line">hadoop@hadoop1:~/my_project_dir$ virtualenv my_project_env</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入虚拟环境</span></span><br><span class="line">hadoop@hadoop1:~/my_project_dir$ <span class="built_in">source</span> my_project_env/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装Jupyter</span></span><br><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ pip install jupyter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置密码</span></span><br><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ jupyter notebook --generate-config</span><br><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ jupyter notebook password</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行Jupyter</span></span><br><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ jupyter notebook</span><br></pre></td></tr></table></figure>
<p>然后Windows+putty通过远程ssh连接使用jupyter notebook：<br>打开putty输入地址：<br><img src="/%22/img/Ubuntu/putty.png%22" alt="img"><br>点击左侧ssh–&gt;tunnel，输入：<br><img src="/%22/img/Ubuntu/putty2.png%22" alt="img"><br>点击add，然后点击open。<br>然后可以在Windows浏览器上输入loacalhost:8000访问linux上的jupyter了。</p>
<p>参考链接：<a target="_blank" rel="noopener" href="https://www.digitalocean.com/community/tutorials/how-to-set-up-jupyter-notebook-with-python-3-on-ubuntu-20-04-and-connect-via-ssh-tunneling">How To Set Up Jupyter Notebook with Python 3 on Ubuntu 20.04</a></p>
<p>安装pip时遇到报错，如下命令解决：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove python-pip-whl</span><br><span class="line">sudo apt -f install</span><br><span class="line">sudo apt update &amp;&amp; sudo apt dist-upgrade</span><br><span class="line">sudo apt install python3-pip</span><br></pre></td></tr></table></figure>

<h3 id="2-5-在Windows上安装PySpark"><a href="#2-5-在Windows上安装PySpark" class="headerlink" title="2.5 在Windows上安装PySpark"></a>2.5 在Windows上安装PySpark</h3><p>首先进入虚拟环境，然后执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ pip install pyspark==3.0.3</span><br><span class="line"><span class="comment"># pyspark版本必须和spark一致，否则pyspark无法在jupyter上正常运行</span></span><br><span class="line"></span><br><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ pyspark</span><br></pre></td></tr></table></figure>

<p>参考链接：<a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/getting_started/install.html">Installation</a></p>
<h2 id="3-使用Spark"><a href="#3-使用Spark" class="headerlink" title="3 使用Spark"></a>3 使用Spark</h2><h3 id="3-1-使用Python-Spark-Shell"><a href="#3-1-使用Python-Spark-Shell" class="headerlink" title="3.1 使用Python Spark Shell"></a>3.1 使用Python Spark Shell</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ pyspark</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; from pyspark import SparkContext</span><br><span class="line">&gt;&gt;&gt; sc = SparkContext(<span class="string">&#x27;local[*]&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; txt = sc.textFile(<span class="string">&#x27;file:///YourFileDirectory/input/try1.txt&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(txt.count())</span><br><span class="line">&gt;&gt;&gt; as_lines = txt.filter(lambda line: <span class="string">&#x27;as&#x27;</span> <span class="keyword">in</span> line.lower())</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(as_lines.count())</span><br></pre></td></tr></table></figure>

<h3 id="3-2-使用spark-submit"><a href="#3-2-使用spark-submit" class="headerlink" title="3.2 使用spark-submit"></a>3.2 使用spark-submit</h3><p>将python代码写好存放于try1.py中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[*]&#x27;</span>)</span><br><span class="line">sc.setLogLevel(<span class="string">&#x27;WARN&#x27;</span>)</span><br><span class="line"></span><br><span class="line">txt = sc.textFile(<span class="string">&#x27;file:///YourFileDirectory/input/try1.txt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(txt.count())</span><br><span class="line"></span><br><span class="line">as_lines = txt.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line: <span class="string">&#x27;as&#x27;</span> <span class="keyword">in</span> line.lower())</span><br><span class="line"><span class="built_in">print</span>(as_lines.count())</span><br></pre></td></tr></table></figure>
<p>然后在命令行执行spark-submit批处理执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(my_project_env)hadoop@hadoop1:~/my_project_dir$ spark-submit try1.py</span><br></pre></td></tr></table></figure>

<h3 id="3-3-使用jupyter-notebook"><a href="#3-3-使用jupyter-notebook" class="headerlink" title="3.3 使用jupyter notebook"></a>3.3 使用jupyter notebook</h3><p>参考2.4中的步骤，运程连接jupyter notebook，将python代码复制到.ipynb文件中执行。</p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="/audio/破茧.mp3">
            </audio>
            
        </div>
        
    <div id="gitalk-container" class="comment link"
		data-enable="true"
        data-ae="false"
        data-ci="2ee3dab371fc6b926450"
        data-cs="80e3a063b0563b737e2a880855076d981e3d195a"
        data-r="yang-xiaoyuan.github.io"
        data-o="yang-xiaoyuan"
        data-a="*"
        data-d="false"
    >查看评论</div>


    </div>
    
        <div class="side">
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Spark%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">1 Spark简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85Spark"><span class="toc-number">2.</span> <span class="toc-text">2 安装Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%AE%89%E8%A3%85scala"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 安装scala</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%AE%89%E8%A3%85spark"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 安装spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E8%BF%90%E8%A1%8C%E6%B5%8B%E8%AF%95%E7%A8%8B%E5%BA%8F"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 运行测试程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E5%AE%89%E8%A3%85Jupyter-notebook%E5%92%8Cpython3"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 安装Jupyter notebook和python3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E5%9C%A8Windows%E4%B8%8A%E5%AE%89%E8%A3%85PySpark"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 在Windows上安装PySpark</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%BD%BF%E7%94%A8Spark"><span class="toc-number">3.</span> <span class="toc-text">3 使用Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E4%BD%BF%E7%94%A8Python-Spark-Shell"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 使用Python Spark Shell</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E4%BD%BF%E7%94%A8spark-submit"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 使用spark-submit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E4%BD%BF%E7%94%A8jupyter-notebook"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 使用jupyter notebook</span></a></li></ol></li></ol>	
        </div>
    
</div>


    </div>
</div>
</body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>






</html>
